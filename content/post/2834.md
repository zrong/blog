+++
title = "Sora 文章汇总"
postid = 2834
date = 2024-02-19T17:48:55+08:00
isCJKLanguage = true
toc = true
type = "post"
slug = "sora-articles"
description = "十几篇文章读了读，总结了一下要点给大家，方便进行快速理解。"
featured = true
draft = false
aliases = [ "/post/2834.html",]
# menu: main
thumbnail = "/uploads/2024/02/2834a.png"
codeMaxLines = 10
codeLineNumbers = true
figurePositionShow = true
category = [ "impressions" ]
tag = ["ai"]
+++

这两天 Sora 的消息满天飞了，我找了十几篇文章读了读，总结了一下要点给大家，方便进行快速理解。 <!--more-->

# 技术向

[OpenAI 的 Sora 技术报告详解](https://mp.weixin.qq.com/s/MyWPPY19wwsJv8zdBMxdFg)

OpenAI 的研究论文 [Video generation models as world simulators](https://openai.com/research/video-generation-models-as-world-simulators)

论文关键点（来自 知白 白话AI编程）：

> 1. 统一的视觉数据表示：研究者们将所有类型的视觉数据转换为统一的表示，以便进行大规模的生成模型训练。Sora 使用视觉补丁（patches）作为其表示方式，类似于大型语言模型（LLM）中的文本标记。
> 2. 视频压缩网络：研究者们训练了一个网络，将原始视频压缩到一个低维潜在空间，并将其表示分解为时空补丁。Sora 在这个压缩的潜在空间中进行训练，并生成视频。
> 3. 扩散模型：Sora 是一个扩散模型，它通过预测原始“干净”的补丁来从输入的噪声补丁中生成视频。扩散模型在语言建模、计算机视觉和图像生成等领域已经显示出了显著的扩展性。
> 4. 视频生成的可扩展性：Sora 能够生成不同分辨率、时长和宽高比的视频，包括全高清视频。这种灵活性使得 Sora 能够直接为不同设备生成内容，或者在生成全分辨率视频之前快速原型化内容。
> 5. 语言理解：为了训练文本到视频生成系统，需要大量的视频和相应的文本标题。研究者们应用了在 DALL·E 3 中引入的重新描述技术，首先训练一个高度描述性的标题生成器，然后为训练集中的所有视频生成文本标题。
> 6. 图像和视频编辑：Sora 不仅能够基于文本提示生成视频，还可以基于现有图像或视频进行提示。这使得 Sora 能够执行广泛的图像和视频编辑任务，如创建完美循环的视频、动画静态图像、向前或向后扩展视频等。
> 7. 模拟能力：当视频模型在大规模训练时，它们展现出了一些有趣的新兴能力，使得 Sora 能够模拟物理世界中的某些方面，如动态相机运动、长期一致性和对象持久性等。

[量子位：爆火Sora参数规模仅30亿？](https://mp.weixin.qq.com/s/ZpZJ9XpbH8QYarMbxXM6SQ)

> - 英伟达AI科学家Jim Fan认为：Sora应该是一个数据驱动的物理引擎。
> - 谢赛宁认为： Sora是视频生成的GPT-3时刻。

[信息平权：继续解读Sora、超微SMCI暴跌](https://mp.weixin.qq.com/s/-jgzQyDSXIi-Fb-BygWqOg)

> 这次创新的关键，可能在于找到了表达视频信息最合适的representation，即spaceTime latent patch，进而可以用OpenAI最擅长的“大力出奇迹”去scale up数据和参数规模，不仅实现了更高精度的扩散模型，甚至涌现出了对物理世界和因果关系的理解

[差评：OpenAI今天刷屏的视频模型，是如何做到这么强的？](https://mp.weixin.qq.com/s/TDVYC4SKlKOGMB99NGESdw)

> OpenAI 在训练上的路线选择也稍有不同。他们选择了 “ 原始尺寸、时长 ” 训练，而非业内常用的 “ 把视频截取成预设标准尺寸、时长 ” 后再训练。

[格隆：OpenAI炸裂升级！又一个行业被干掉了](https://mp.weixin.qq.com/s/-K2DbTMocoNtK8s5R8voUw)

> Sora主要采用了两种技术。
> 
> - 一个是扩散模型（diffusion model），原本是用于文字转图片的。Sora的团队使用了DALL-E 3背后的技术，即扩散模型。扩散模型经过训练后可以将模糊的随机像素变成图片。
> - 另一项技术是Transformer的神经网络，就是GPT（Generative Pre-Trained Transformer）中的T。Transformer 架构中，全注意力机制的内存需求会随着输入序列长度而二次方增长，计算成本太高了。所以他们开发了一个视频压缩网络，先把视频数据降维到latent（潜空间），再将压缩过的数据生成 Patche，这样就能使输入的信息变少，有效减小计算量压力。然后，为了让大模型更好理解用户的意思，OpenAI 直接把文生视频模型套进已经得到市场认可的GPT模型范式中，这就是它独有的优势了。

[AIGC开放社区：OpenAI公布Sora技术报告：模拟世界、视频扩展等，强的离谱！](https://mp.weixin.qq.com/s/f-gWdiwWPvV5PX-dFIUXaA)

> 为什么其他模型，很难生成4秒以上的高质量视频？ 一个重要原因就是缺少——高质量训练数据。
>
> Sora在经过大规模训练后，会表现出许多有趣的新能力，能够模拟物理世界中的人、动物和环境的某些方面。
> 
> Sora 拥有视频连接功能，扩展生成视频功能，视频剪辑能力。


[量子位：Sora背后团队：应届博士带队，00后入列，还专门招了艺术生](https://mp.weixin.qq.com/s/ggST2FiiUN8AgCApKWIh4Q)

> 应届博士带队，多名 DALL-E 的创作者。

# 内容影响

[互联网怪盗团：Sora会对视频内容创作产生什么样的影响？](https://mp.weixin.qq.com/s/eGrkahMNblphOmYESvQSsw)

![内容调性和热感敏感](/uploads/2024/02/2834a.png)

裴团长的观点总结：对于热点话题的“时效性覆盖”将主要是AI的任务，这方面很难玩出花来。优质的垂类创作者更容易从AI中找到自己的优势。

[果壳：关于 Sora，我有十个小白问题](https://mp.weixin.qq.com/s/xu5L4ZtFyJ1XyD15_8vf0Q)

> Sora 在日语中是“天空”的意思，引申含义还有“自由”。
>
> 虽然 Sora 都还没公测呢，但已经有人开始卖付费教程了。

[腾讯科技：Sora“碾压”一众模型，Pika等创业公司再无活路？](https://mp.weixin.qq.com/s/U5_Wvo9rdDUjAH0SG748rQ)

> 从ChatGPT、DALL-E3，再到Sora，如果用一句话来总结OpenAI的与众不同之处，那就是：技术想象力和工程能力，要远比技术路线或者黑科技重要。
>
> Sora爆发的当下，普通人要做的事情可以归结为三件事：
> 1.  应用到你熟悉的场景中
> 2.  探索属于你的新模式
> 3.  成为规则的“领航员”

[字母榜：Sora会“杀死“剪映吗？](https://mp.weixin.qq.com/s/eJtx9jAUb7IGkcF6mSlSrw)

> 张楠卸任抖音CEO，投入全部精力用AI改造剪映，被外界视为是字节内部希望提速AI发展的一个信号。

{{< label 全文完 >}}